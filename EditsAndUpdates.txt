Edits And Updates:


Code changes, and comments. Rather than typing shit in for commits,
use this file to add notes about what changed to files, the push 
with the rest of the stuff. Include date. Newest changes at top.


06/25/2019:
--Noncausal np.roll(). Disappointed.


06/24/2019:
--More updates on the night: minor bug fixes, allowing for trades
to execute the day after selling, as well as fixing ma compution.
--Ditching seperate functions, simple if/else for now.
--Minor bug fix in scraping capability
--Added 60:30:10 split, watchlist plot generation
--Next add: save weights/bias for pythonista


06/21/2019:
--Major changes in download_quotes(). Added actual 'scraping' capability
so redownload of entire history doesn't need to happen each time. Dear 
god this took longer than I wanted it to. 
--Fixed bad cookie value by re-querying the url until it works (becasue 
I know the data exists and is accessable). Feels a bit hackish but will 
work for now.
--Next add: 60:30:10 splits, seperate functions for download+scrape, NN.



06/18/2019:
--Analytics included. Testing on penny (5%pg labels), performing 
fire so far.
--Watchlist generation and plotting
--File for saving models
--Next to add, pure scraping functionality and dealing with bad cookies.


06/17/2019:
--Mass data training. Analytics are next. Looking pretty cherry.


06/03/2019:
--Major architecture changes implemented, and in the works. Basically
making shit easier to work with in general, for training on shit tons
of data at once. Boils down to less typing but more confusion with 
indicies. Just need to keep the dictionary up to date and all shall be
well.
--Bug fix in download quotes, not getting all stocks (missing one).


05/22/2019:
--8 new attributes. Hella performacne. Getting the itch to go ham on this
in a few weeks. Optimistic


05/09/2019: 
--Holy fuck I lost track of all of the updates, but shit is
working well from a functionality point of view. Changed all the stuff
to be in the numpy framework #fuckpandas. Mostly want to try running the
scrape from my iPhone #AppleGang. Getting back after it.


11/15/2018:
--More progress here. Testing simplified version of NN, only two layers.
Seems to train better.
--Implemented simple trading strategy w/visulaization. Interesting to 
play with here but need to make better trading strategy as well as 
train up the net with more parameters.
--Currently thinking binary moving average correlation matrix. HI_LOW 
LOW_HI sort of deal. This is important for lots of traders. 
--Happy with how things are progressing here doe.


11/08/2018: 
--AYO making progress here. ANN w/shitty indicators didnt work AT ALL,
however I grew a pair and went IN on the d1, d2, d3's (lmao) and getting 
some interesting results here.
--Changes basically adding indicators, sticking with BINARY classification
for now - regression models did NOT work - something fundamental going on 
there I think. 
--Stoke is high.


10/30/2018:
--Added make_labels_percent_gain function to assign a label to every day
where the stock increased above a threshold percentage. will use this to 
create ANN for classification. 
--Added method to StockClass to filter out nans. not sure how else to 
deal with this issue (also was a major bitch to get this working).
--Deleted a few delisted stocks from the data set to avoid errors
--Put the ticker import into a function called gather_tickers
--Added dope waitbar function
--Just about ready to make a first crack an ANN for use with a trading algo.
My idea is as follows: train ANN to spit out 1 for buy, 0 for sell on a day
befor stock is predicted to increase by some threshold percentage. compute 
this at the end of each day to determine whether to hold or sell stock the
following morning or in AH. an extention of this is to use regression or a 
finer classification to get a specific percentage change for following day, 
and perform larger iterative prediction (almost like recursion) to map out a 
trade plan. so: prediction1--> ANN--> prediction2--> ANN--> prediction3-->,
can use this n times and compare against realitiy for loss function in that 
sense. 
--Other ideas include computing indicator and performing k-means clustering,
would probably require normalizaiton of data. 
--Eventually would like to integrate DMD to correlate modes with buy signals.



10/19/2018:
--Added sector to each stock in SP500_Labels.txt. 
--Added additional class atribute called sector to identify each
 stocks sector. Changed stock.name to stock.ticker. 
--Upated methods to use symbol[i][0] b/c of sector additon.
--Would be nice to figure out how to get all the "tickers =" into 1 or 2 
lines instead of the 5 it currently uses. 


10/15/2018:
-- created a class StockClass to use for making all these instances of
stocks and stuff. not an expert in what this is doing exaclty but basically
trying to make things similar to how i had them in matlab. this will work 
for now. 
--parse_csv is used to get all the data from the csv files to the stock
variable which is a big ass list of stock classes. 
-- this is dope process. now we (i?) can actually start doing some data
processing and get this bish rolling!


10/4/2018: 
--scrapeData takes in list of S$P 500 stocks, saves to folder
which is defined in get_data. I set the path to be some other folder
outside of where I keep everything else to avoid clutter. Minor changes 
to methods to allow for null cookie values.
--in general, dont fuck with the CSVFiles folder. this should just be used
for some data storage, and as a backup for now.
--added this file to talk about changes.
